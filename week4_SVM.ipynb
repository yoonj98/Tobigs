{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HyMvTfrPTEU"
   },
   "source": [
    "## Tobigs 4주차 SVM 과제 - Multiclass SVM\n",
    "#### 15기 이윤정\n",
    "---\n",
    "기본적으로 SVM은 binary classification이므로 multi classification을 하기 위해서는 2가지 방법이 존재한다.   \n",
    "    1. One vs Rest  \n",
    "    2. One vs One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMqxwjbRNX6u",
    "outputId": "f7b6519f-9521-446b-a107-044a7113bc08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#IRIS 데이터 로드\n",
    "iris =  sns.load_dataset('iris') \n",
    "X= iris.iloc[:,:4] #학습할데이터\n",
    "y = iris.iloc[:,-1] #타겟\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tm8gpfVSNX67"
   },
   "outputs": [],
   "source": [
    "scal = StandardScaler() #scaling\n",
    "X = scal.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "laRcz10bNX7C",
    "outputId": "66f6f6c2-38fb-4da2-bb76-560838244c24",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7VgXR-SNX7K"
   },
   "outputs": [],
   "source": [
    "# One VS Rest 구현을 위해 1) class가 0 or not 2)class가 1 or not을 구분하기 위한 머신 등을 미리 만들어주자\n",
    "svm_1 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_2 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_3 = SVC(kernel ='rbf', C = 5, gamma = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyMSHOFHNX7R"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #test/train 데이터로 분리\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KnlaqAJNX7X"
   },
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train) #one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
      "[-1.12470845 -0.86326953 -0.65281099 -0.50248821 -0.76284323 -0.87465573\n",
      "  1.07709345 -0.99281647  0.47441336 -0.99842743 -0.83989348  0.15633457\n",
      "  0.32871788 -0.97965464 -0.72385083 -0.92638376  1.28322481 -0.56240455\n",
      " -0.72719892 -0.99509775  0.43166724 -0.96451557 -0.82991366 -1.03020581\n",
      " -0.75166835  1.13461335  0.39943974 -1.04194106 -0.93376548 -1.06133798]\n"
     ]
    }
   ],
   "source": [
    "svm_1.fit(X_train,y_train.iloc[:,0]) # 데이터 클레스가 0 or not 구분해주는 머신\n",
    "svm_2.fit(X_train,y_train.iloc[:,1]) # 데이터 클레스가 1 or not 구분해주는 머신\n",
    "svm_3.fit(X_train,y_train.iloc[:,2]) # 데이터 클레스가 2 or not 구분해주는 머신\n",
    "print(svm_1.predict(X_test)) #데이터 클래스가 0 or not을 구분해주는 애를 통해서 테스트 데이터의 클래스가 0인지, 0이 아닌인지 예측해보자\n",
    "\n",
    "print(svm_1.decision_function(X_test)) #decision_function hyperplane과의 거리를 구하는 방법(필요하다면 활용해주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCR46aMrNX7p",
    "outputId": "ec7adcec-d0e8-4dd8-f2df-4cd063a19867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "17\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# 부호가 모든 같은 경우가 있는가? > 모두 동점인 경우가 생길 것\n",
    "for i in range(len(X_test)):\n",
    "    # ~. decision_function을 이용하면 해당 데이터가 하이퍼플레인으로부터 얼마나 떨어져있는지 '거리'가 나온다!\n",
    "    # 다음은 그 값의 부호를 이용해 모두가 동점인 경우가 있는지 출력하는 함수 \n",
    "    if (np.sign(svm_1.decision_function(X_test)[i]) == np.sign(svm_2.decision_function(X_test)[i])) and (np.sign(svm_2.decision_function(X_test)[i]) == np.sign(svm_3.decision_function(X_test)[i])):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## One vs Rest(All) SVM\n",
    ": 전체 class의 수가 M개 일때, 각 class 별로 해당 class(1) vs 이외의 class(m-1)로 binary decision을 한 다음 Hypothesis function 값이 가장 큰 값을 고르는 방법  \n",
    "이때, Hypothesis function 값은 주어진 x가 해당 class에 들어갈 확률이므로 Hypothesis function 값이 크다는 것은 해당 class에 들어갈 확률이 가장 크다는 것을 의미한다.  \n",
    "\n",
    "**문제점**  \n",
    "    1. Hypothesis function value = 초평면값의 크기를 단순 비교하여 값을 찾는다는 점이 비합리적일 수 있다.   \n",
    "    2. binary classifier의 training set이 불균형하다. (1 : m-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'setosa', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'versicolor', 'versicolor', 'setosa', 'versicolor', 'virginica', 'virginica', 'setosa', 'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'virginica', 'versicolor']\n",
      "Accuacy :  0.86667\n"
     ]
    }
   ],
   "source": [
    "## Case 1 : One vs Rest SVM을 이부분에 구현해주세요 위 결과들을 이용해서 multi class SVM을 직접 구현해주세요! 하드코딩이 하시기 편할겁니다.\n",
    "\n",
    "#해당 class vs 이외 class 간의 결과를 기반으로 한 투표 진행\n",
    "array = [[0 for j in range(3)] for i in range(len(X_test))] #svm 결과 저장할 2차원 배열 선언 및 초기화\n",
    "y_pred = []\n",
    "\n",
    "for i in range(0, len(X_test)):  #binary classification SVM 시 자신의 class로 분류한 경우 1로 대입\n",
    "    if svm_1.predict(X_test)[i] == 1:\n",
    "        array[i][0] = 1\n",
    "    elif svm_2.predict(X_test)[i] == 1:\n",
    "        array[i][1] = 1\n",
    "    elif svm_3.predict(X_test)[i] == 1:\n",
    "        array[i][2] = 1\n",
    "    \n",
    "    #동점자 처리 - decision_function 이용\n",
    "    ## case1 - 모두 자신의 class가 아니라고 분류한 경우 = All 0 \n",
    "    if (array[i][0] == 0) and (array[i][1] == 0) and (array[i][2] == 0):\n",
    "        y_pred.append(np.argmax([svm_1.decision_function(X_test)[i], svm_2.decision_function(X_test)[i], svm_3.decision_function(X_test)[i]]))\n",
    "        \n",
    "    ## case2 - 2개 이상의 class에서 자신의 class라고 분류한 경우\n",
    "    elif (array[i][0] == 1) and (array[i][1] == 1):\n",
    "        y_pred.append(np.argmax([svm_1.decision_function(X_test)[i], svm_2.decision_function(X_test)[i]]))  \n",
    "    elif (array[i][0] == 1) and (array[i][2] == 1):\n",
    "        y_pred.append(np.argmax([svm_1.decision_function(X_test)[i], svm_3.decision_function(X_test)[i]]))\n",
    "    elif (array[i][1] == 1) and (array[i][2] == 1):\n",
    "        y_pred.append(np.argmax([svm_2.decision_function(X_test)[i], svm_3.decision_function(X_test)[i]]))\n",
    "    \n",
    "    ## 그외    \n",
    "    else:\n",
    "        y_pred.append(np.argmax(array[i]))  #가장 큰 값을 예측값으로 선정\n",
    "\n",
    "label = []\n",
    "for j in range(0, len(y_pred)):  #labeling\n",
    "    if y_pred[j] == 0:\n",
    "        label.append('setosa')\n",
    "    elif y_pred[j] == 1:\n",
    "        label.append('versicolor')\n",
    "    elif y_pred[j] == 2:\n",
    "        label.append('virginica')\n",
    "        \n",
    "print(label)\n",
    "print('Accuacy : {: .5f}'.format(accuracy_score(y_test, label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## One vs One SVM\n",
    ": 전체 class의 수가 M개 일때, 모든 Class에 대해 1 vs 1로 SVM을 여러개 만들고 확장하는 방식. M개의 클래스 중 2개를 선택하여 두 Class에 대한 결정 초평면을 만든다. (이때, 결정 초평면은 mC2개)   \n",
    "이후, 새로 들어온 sample에 대해 결정 초평면이 class A로 분류하는 경우 class A에 +1, class B로 분류하는 경우 class B에 +1로 투표한다. 이렇게 모든 결정 초평면에 대해 분류하였을 때, 가장 높은 점수를 획득한 class가 예측된 class이다. (이때, 얻을 수 있는 최대 표 값은 M-1개)\n",
    "\n",
    "**문제점**  \n",
    "- SVM의 개수가 기하급수적으로 증가한다.   \n",
    "- SVM의 개수가 증가함에 따라 learning과 test에 걸리는 시간이 증가한다.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원래 라이브러리가 제공하는 multi class SVM과 여러분이 구현한 multiclass SVM 결과를 비교해주세요\n",
    "from sklearn.model_selection import train_test_split #데이터셋 분리\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "\n",
    "svm_4 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_4.fit(X_train_2, y_train_2)\n",
    "y_pred = svm_4.predict(X_test_2)\n",
    "\n",
    "# metrics.accuracy_score(y_test_2,y_pred)\n",
    "accuracy_score(y_test_2,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One vs Rest SVM으로 직접 구현하였을 때, Accuacy score = 0.86667이다. 이때, sklearn에서 제공하는 multiclass svm의 Accuacy score = 0.8666666666666667으로 동일한 결과가 도출되었다. 그러므로, 직접 구현한 One vs Rest SVM은 정상 작동된다고 볼 수 있다. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "assignment_1.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
